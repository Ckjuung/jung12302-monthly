
import requests, xmltodict, pandas as pd
import datetime
from dateutil.relativedelta import relativedelta

today = datetime.date(2025, 4, 1)
start_date = today - relativedelta(months=1)
end_date = today - datetime.timedelta(days=1)
target_month = start_date.strftime("%Y%m")

service_key = "DBL9%2FjevAhTCfpDi5RqbnF61jt1lxJGlxxUSW%2F7mv4GB9bDJk6F1V%2B2izfb51UFSFtAGXxQ89Xy89pk4VFOMuQ%3D%3D"
gu_list = {
    "ê°•ë‚¨êµ¬": "11680", "ì„œì´ˆêµ¬": "11650", "ì†¡íŒŒêµ¬": "11710", "ì„±ë™êµ¬": "11200",
    "ë™ì‘êµ¬": "11590", "ê´‘ì§„êµ¬": "11215", "ë™ëŒ€ë¬¸êµ¬": "11230", "ë§ˆí¬êµ¬": "11440", "ê°•ë™êµ¬": "11740"
}
url_base = "http://apis.data.go.kr/1613000/RTMSDataSvcAptTradeDev/getRTMSDataSvcAptTradeDev"

all_data = []
for gu, code in gu_list.items():
    url = f"{url_base}?serviceKey={service_key}&LAWD_CD={code}&DEAL_YMD={target_month}&numOfRows=1000"
    try:
        r = requests.get(url)
        parsed = xmltodict.parse(r.content)
        items = parsed.get("response", {}).get("body", {}).get("items", {}).get("item", [])
        if items:
            if isinstance(items, dict): items = [items]
            for item in items:
                item['sggNm'] = gu
                all_data.append(item)
    except Exception as e:
        print(f"â— {gu} ìš”ì²­ ì‹¤íŒ¨: {e}")
        continue

# âœ… ì‘ë‹µ ë¹„ì—ˆì„ ê²½ìš° ì¤‘ë‹¨
if not all_data:
    raise ValueError("ğŸš« APIë¡œë¶€í„° ìˆ˜ì‹ ëœ ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")

df = pd.DataFrame(all_data)

# âœ… 'sggNm' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ì¤‘ë‹¨
if 'sggNm' not in df.columns:
    raise ValueError("ğŸš¨ 'sggNm' ì»¬ëŸ¼ì´ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. API ì‘ë‹µì´ ë¹„ì–´ ìˆê±°ë‚˜ ì˜ëª»ë¨.")

# ì „ì²˜ë¦¬
for col in ['dealYear', 'dealMonth', 'dealDay', 'excluUseAr', 'dealAmount', 'dealingGbn', 'sggNm']:
    if col not in df.columns: df[col] = None
df['ê±°ë˜ì¼'] = pd.to_datetime(df['dealYear'] + df['dealMonth'].str.zfill(2) + df['dealDay'].str.zfill(2), errors='coerce')
df = df[(df['ê±°ë˜ì¼'] >= pd.Timestamp(start_date)) & (df['ê±°ë˜ì¼'] <= pd.Timestamp(end_date))]
df['excluUseAr'] = pd.to_numeric(df['excluUseAr'], errors='coerce')
df['ê±°ë˜ê¸ˆì•¡(ë§Œì›)'] = df['dealAmount'].str.replace(",", "").astype(int)
df = df[df['dealingGbn'] == 'ì¤‘ê°œê±°ë˜']

def classify_group(area):
    if 50.0 <= area < 60.0: return 'ê·¸ë£¹1 (50~60ã¡)'
    elif 80.0 <= area <= 85.0: return 'ê·¸ë£¹2 (80~85ã¡)'
    else: return None

df['ë©´ì ê·¸ë£¹'] = df['excluUseAr'].apply(classify_group)
df = df[df['ë©´ì ê·¸ë£¹'].notnull()]

lines = []
lines.append(f"# ğŸ“Š {start_date.strftime('%Yë…„ %mì›”')} ì‹¤ê±°ë˜ê°€ ë³´ê³ ì„œ (ì „ìš©ë©´ì  ê·¸ë£¹ë³„ Top3)\n")

for idx, gu in enumerate(gu_list, start=1):
    lines.append(f"## {idx}. {gu}")
    df_gu = df[df['sggNm'] == gu]
    for group in ['ê·¸ë£¹1 (50~60ã¡)', 'ê·¸ë£¹2 (80~85ã¡)']:
        df_grp = df_gu[df_gu['ë©´ì ê·¸ë£¹'] == group]
        if df_grp.empty:
            lines.append(f"- **{group}**: ê±°ë˜ ì—†ìŒ\n")
            continue
        lines.append(f"\n- **{group}**")
        top3 = (
            df_grp.groupby('aptNm')
            .agg(ê±°ë˜ê±´ìˆ˜=('ê±°ë˜ì¼', 'count'))
            .sort_values('ê±°ë˜ê±´ìˆ˜', ascending=False)
            .head(3)
            .reset_index()
        )
        for i, row in top3.iterrows():
            apt = row['aptNm']
            count = row['ê±°ë˜ê±´ìˆ˜']
            df_apt = df_grp[df_grp['aptNm'] == apt]
            avg = round(df_apt['ê±°ë˜ê¸ˆì•¡(ë§Œì›)'].mean())
            maxp = df_apt['ê±°ë˜ê¸ˆì•¡(ë§Œì›)'].max()
            minp = df_apt['ê±°ë˜ê¸ˆì•¡(ë§Œì›)'].min()
            lines.append(f"    - {i+1}ìœ„: {apt} ({count}ê±´, í‰ê·  {avg:,}ë§Œì›, ìµœê³ ê°€ {maxp:,}ë§Œì›, ìµœì €ê°€ {minp:,}ë§Œì›)")

with open(f"report_{start_date.strftime('%Y_%m')}.md", "w", encoding="utf-8") as f:
    f.write("\n".join(lines))
